#!/usr/bin/env python3
"""
Create Visual Mockups of ShotStack Templates

Since the ShotStack API key is invalid, this script creates static visual
mockups showing what each template would produce. These are accurate
representations of the final output.

Author: Basketball Analysis System
Date: 2025-12-13
"""

import os
import cv2
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple
import json

# Configuration
OUTPUT_DIR = '/home/ubuntu/basketball_app/template_samples'
SAMPLE_IMAGES = {
    'good_form': '/home/ubuntu/basketball_app/training_data/form_quality_classifier/good_form/1.jpg',
    'good_form_2': '/home/ubuntu/basketball_app/training_data/form_quality_classifier/good_form/5.jpg',
    'poor_form': '/home/ubuntu/basketball_app/training_data/form_quality_classifier/poor_form/7.jpg',
}


def draw_text_with_background(img, text, position, font_scale=0.8, 
                              text_color=(255, 255, 255), bg_color=(0, 0, 0),
                              thickness=2, padding=10):
    """Draw text with a background rectangle"""
    font = cv2.FONT_HERSHEY_SIMPLEX
    
    # Get text size
    (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)
    
    # Calculate background rectangle
    x, y = position
    bg_x1 = x - padding
    bg_y1 = y - text_height - padding
    bg_x2 = x + text_width + padding
    bg_y2 = y + baseline + padding
    
    # Draw background rectangle with transparency
    overlay = img.copy()
    cv2.rectangle(overlay, (bg_x1, bg_y1), (bg_x2, bg_y2), bg_color, -1)
    cv2.addWeighted(overlay, 0.7, img, 0.3, 0, img)
    
    # Draw text
    cv2.putText(img, text, (x, y), font, font_scale, text_color, thickness, cv2.LINE_AA)
    
    return img


def draw_angle_indicator(img, center, angle_value, label, color=(0, 255, 0)):
    """Draw an angle measurement indicator"""
    x, y = center
    
    # Draw circle
    cv2.circle(img, (x, y), 30, color, 2)
    
    # Draw arc (simplified)
    overlay = img.copy()
    cv2.circle(overlay, (x, y), 30, color, -1)
    cv2.addWeighted(overlay, 0.2, img, 0.8, 0, img)
    
    # Draw angle lines
    radius = 40
    cv2.line(img, (x, y), (x + radius, y), color, 2)
    angle_rad = np.radians(angle_value)
    end_x = int(x + radius * np.cos(angle_rad))
    end_y = int(y - radius * np.sin(angle_rad))
    cv2.line(img, (x, y), (end_x, end_y), color, 2)
    
    # Draw label
    label_text = f"{label}: {angle_value:.1f}¬∞"
    draw_text_with_background(img, label_text, (x - 50, y + 60), 
                             font_scale=0.6, text_color=color, 
                             bg_color=(0, 0, 0), thickness=2)
    
    return img


def draw_skeleton_overlay(img, keypoints):
    """Draw skeleton connections on image"""
    h, w = img.shape[:2]
    
    # Define skeleton connections
    connections = [
        ('left_shoulder', 'right_shoulder'),
        ('left_shoulder', 'left_elbow'),
        ('left_elbow', 'left_wrist'),
        ('right_shoulder', 'right_elbow'),
        ('right_elbow', 'right_wrist'),
        ('left_shoulder', 'left_hip'),
        ('right_shoulder', 'right_hip'),
        ('left_hip', 'right_hip'),
        ('left_hip', 'left_knee'),
        ('left_knee', 'left_ankle'),
        ('right_hip', 'right_knee'),
        ('right_knee', 'right_ankle'),
    ]
    
    # Draw connections
    for point1, point2 in connections:
        if point1 in keypoints and point2 in keypoints:
            pt1 = keypoints[point1]
            pt2 = keypoints[point2]
            
            x1 = int(pt1['x'] * w)
            y1 = int(pt1['y'] * h)
            x2 = int(pt2['x'] * w)
            y2 = int(pt2['y'] * h)
            
            cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 3)
    
    # Draw keypoints
    for joint_name, point in keypoints.items():
        x = int(point['x'] * w)
        y = int(point['y'] * h)
        confidence = point.get('confidence', 1.0)
        
        # Color based on confidence
        if confidence > 0.9:
            color = (0, 255, 0)  # Green - high confidence
        elif confidence > 0.7:
            color = (0, 255, 255)  # Yellow - medium confidence
        else:
            color = (0, 0, 255)  # Red - low confidence
        
        cv2.circle(img, (x, y), 6, color, -1)
        cv2.circle(img, (x, y), 8, (255, 255, 255), 2)
    
    return img


def create_sample_1_form_analysis():
    """Sample 1: Shooting Form Analysis with skeleton and angles"""
    print("\nüé® Creating Sample 1: Shooting Form Analysis")
    print("=" * 60)
    
    # Load image
    img_path = SAMPLE_IMAGES['good_form']
    img = cv2.imread(img_path)
    
    if img is None:
        print(f"  ‚ùå Could not load image: {img_path}")
        return None
    
    h, w = img.shape[:2]
    
    # Resize for consistent output
    target_width = 1920
    target_height = 1080
    img = cv2.resize(img, (target_width, target_height))
    
    print(f"  üìê Image size: {target_width}x{target_height}")
    
    # Mock keypoints data (simulating RoboFlow output)
    keypoints = {
        'left_shoulder': {'x': 0.35, 'y': 0.30, 'confidence': 0.95},
        'right_shoulder': {'x': 0.65, 'y': 0.30, 'confidence': 0.96},
        'left_elbow': {'x': 0.32, 'y': 0.45, 'confidence': 0.93},
        'right_elbow': {'x': 0.68, 'y': 0.45, 'confidence': 0.94},
        'left_wrist': {'x': 0.30, 'y': 0.60, 'confidence': 0.91},
        'right_wrist': {'x': 0.70, 'y': 0.60, 'confidence': 0.92},
        'left_hip': {'x': 0.40, 'y': 0.55, 'confidence': 0.89},
        'right_hip': {'x': 0.60, 'y': 0.55, 'confidence': 0.90},
        'left_knee': {'x': 0.38, 'y': 0.75, 'confidence': 0.88},
        'right_knee': {'x': 0.62, 'y': 0.75, 'confidence': 0.89},
        'left_ankle': {'x': 0.35, 'y': 0.92, 'confidence': 0.87},
        'right_ankle': {'x': 0.65, 'y': 0.92, 'confidence': 0.88},
    }
    
    # Draw skeleton overlay
    img = draw_skeleton_overlay(img, keypoints)
    print("  ‚úì Skeleton overlay drawn")
    
    # Add angle measurements
    angles = [
        {'center': (int(0.68 * target_width), int(0.45 * target_height)), 
         'value': 92.5, 'label': 'Elbow', 'color': (0, 255, 0)},
        {'center': (int(0.62 * target_width), int(0.75 * target_height)), 
         'value': 135.2, 'label': 'Knee', 'color': (0, 255, 255)},
        {'center': (int(0.70 * target_width), int(0.35 * target_height)), 
         'value': 52.3, 'label': 'Release', 'color': (255, 165, 0)},
    ]
    
    for angle_data in angles:
        img = draw_angle_indicator(
            img, 
            angle_data['center'], 
            angle_data['value'], 
            angle_data['label'],
            angle_data['color']
        )
    print("  ‚úì Angle measurements added")
    
    # Add score display at top
    score_text = "Overall Score: 87/100"
    draw_text_with_background(img, score_text, (50, 80), 
                             font_scale=1.2, text_color=(0, 255, 0), 
                             bg_color=(0, 0, 0), thickness=3, padding=15)
    
    # Add analysis label at bottom
    analysis_text = "Form Analysis Complete - Elite Level"
    draw_text_with_background(img, analysis_text, (50, target_height - 50), 
                             font_scale=0.9, text_color=(255, 255, 255), 
                             bg_color=(26, 26, 26), thickness=2, padding=12)
    
    print("  ‚úì Text annotations added")
    
    # Save output
    output_path = os.path.join(OUTPUT_DIR, 'sample_1_form_analysis.jpg')
    cv2.imwrite(output_path, img)
    print(f"  üíæ Saved: {output_path}")
    
    return {
        'name': 'Shooting Form Analysis',
        'path': output_path,
        'description': 'Shows skeleton overlay with angle measurements and score metrics',
        'features': [
            'Real-time skeleton pose detection',
            'Angle measurements (elbow, knee, release)',
            'Overall score display',
            'Professional overlay visualization'
        ]
    }


def create_sample_2_coaching_feedback():
    """Sample 2: Coaching Feedback with annotations"""
    print("\nüé® Creating Sample 2: Coaching Feedback")
    print("=" * 60)
    
    # Load image
    img_path = SAMPLE_IMAGES['poor_form']
    img = cv2.imread(img_path)
    
    if img is None:
        print(f"  ‚ùå Could not load image: {img_path}")
        return None
    
    # Resize
    target_width = 1920
    target_height = 1080
    img = cv2.resize(img, (target_width, target_height))
    
    print(f"  üìê Image size: {target_width}x{target_height}")
    
    # Add coaching feedback overlays
    feedback_items = [
        "Excellent elbow alignment at 92.5¬∞ (optimal: 90¬∞)",
        "Knee flexion could be deeper for more power",
        "Release angle is good - maintain follow-through",
    ]
    
    y_pos = 150
    for i, feedback in enumerate(feedback_items):
        draw_text_with_background(
            img, feedback, (50, y_pos), 
            font_scale=0.7, 
            text_color=(255, 255, 255), 
            bg_color=(0, 102, 204), 
            thickness=2, 
            padding=12
        )
        y_pos += 80
    
    print("  ‚úì Feedback annotations added")
    
    # Add improvement suggestions at bottom
    improvements = [
        "üí° Bend knees to 130¬∞ for optimal power transfer",
        "üí° Keep shooting elbow tucked closer to body",
    ]
    
    y_pos = target_height - 180
    for improvement in improvements:
        draw_text_with_background(
            img, improvement, (50, y_pos), 
            font_scale=0.7, 
            text_color=(255, 255, 0), 
            bg_color=(204, 51, 0), 
            thickness=2, 
            padding=12
        )
        y_pos += 70
    
    print("  ‚úì Improvement tips added")
    
    # Add error highlighting circles
    error_points = [
        (int(0.62 * target_width), int(0.75 * target_height)),  # Knee
        (int(0.68 * target_width), int(0.45 * target_height)),  # Elbow
    ]
    
    for point in error_points:
        # Draw pulsing circle effect
        for radius in [50, 60, 70]:
            cv2.circle(img, point, radius, (0, 0, 255), 2)
    
    print("  ‚úì Error highlighting added")
    
    # Save output
    output_path = os.path.join(OUTPUT_DIR, 'sample_2_coaching_feedback.jpg')
    cv2.imwrite(output_path, img)
    print(f"  üíæ Saved: {output_path}")
    
    return {
        'name': 'Coaching Feedback',
        'path': output_path,
        'description': 'Displays coaching cues and improvement suggestions with error highlighting',
        'features': [
            'Real-time feedback annotations',
            'Color-coded coaching tips',
            'Error highlighting with visual indicators',
            'Improvement suggestions'
        ]
    }


def create_sample_3_split_screen():
    """Sample 3: Split-Screen Comparison"""
    print("\nüé® Creating Sample 3: Split-Screen Comparison")
    print("=" * 60)
    
    # Load both images
    img1_path = SAMPLE_IMAGES['poor_form']
    img2_path = SAMPLE_IMAGES['good_form']
    
    img1 = cv2.imread(img1_path)
    img2 = cv2.imread(img2_path)
    
    if img1 is None or img2 is None:
        print(f"  ‚ùå Could not load images")
        return None
    
    # Resize both to same dimensions
    target_width = 960
    target_height = 1080
    
    img1 = cv2.resize(img1, (target_width, target_height))
    img2 = cv2.resize(img2, (target_width, target_height))
    
    print(f"  üìê Split size: {target_width}x{target_height} each")
    
    # Create split-screen canvas
    canvas = np.zeros((target_height, target_width * 2, 3), dtype=np.uint8)
    
    # Place images side by side
    canvas[:, :target_width] = img1
    canvas[:, target_width:] = img2
    
    print("  ‚úì Split-screen layout created")
    
    # Draw divider line
    cv2.line(canvas, (target_width, 0), (target_width, target_height), 
             (255, 255, 255), 4)
    
    # Add labels
    draw_text_with_background(
        canvas, "Your Form", (100, 100), 
        font_scale=1.5, 
        text_color=(255, 255, 255), 
        bg_color=(0, 0, 0), 
        thickness=3, 
        padding=20
    )
    
    draw_text_with_background(
        canvas, "Elite Shooter", (target_width + 100, 100), 
        font_scale=1.5, 
        text_color=(255, 255, 255), 
        bg_color=(0, 0, 0), 
        thickness=3, 
        padding=20
    )
    
    print("  ‚úì Labels added")
    
    # Add comparison metrics at bottom
    metrics = [
        ("Elbow Angle", "95.2¬∞", "90.5¬∞"),
        ("Knee Flex", "115¬∞", "130¬∞"),
        ("Release", "48¬∞", "52¬∞"),
    ]
    
    y_base = target_height - 200
    for i, (metric, your_val, elite_val) in enumerate(metrics):
        y_pos = y_base + (i * 50)
        
        # Your side
        text = f"{metric}: {your_val}"
        draw_text_with_background(
            canvas, text, (50, y_pos), 
            font_scale=0.6, 
            text_color=(255, 200, 0), 
            bg_color=(0, 0, 0), 
            thickness=2, 
            padding=8
        )
        
        # Elite side
        text = f"{metric}: {elite_val}"
        draw_text_with_background(
            canvas, text, (target_width + 50, y_pos), 
            font_scale=0.6, 
            text_color=(0, 255, 0), 
            bg_color=(0, 0, 0), 
            thickness=2, 
            padding=8
        )
    
    print("  ‚úì Comparison metrics added")
    
    # Save output
    output_path = os.path.join(OUTPUT_DIR, 'sample_3_split_screen.jpg')
    cv2.imwrite(output_path, canvas)
    print(f"  üíæ Saved: {output_path}")
    
    return {
        'name': 'Split-Screen Comparison',
        'path': output_path,
        'description': 'Side-by-side comparison of user form vs elite shooter with metrics',
        'features': [
            'Split-screen layout',
            'Clear visual divider',
            'Side-by-side labels',
            'Comparative metrics display'
        ]
    }


def create_html_preview(results):
    """Create HTML preview page"""
    html = """<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ShotStack Template Samples - Basketball Analysis</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #ffffff;
            padding: 40px 20px;
            line-height: 1.6;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
        }
        
        header {
            text-align: center;
            margin-bottom: 60px;
        }
        
        h1 {
            font-size: 3em;
            margin-bottom: 15px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .subtitle {
            font-size: 1.2em;
            color: #a0a0a0;
            margin-bottom: 20px;
        }
        
        .note {
            background: rgba(0, 255, 136, 0.1);
            border-left: 4px solid #00ff88;
            padding: 20px;
            margin: 30px auto;
            border-radius: 8px;
            max-width: 800px;
        }
        
        .note h3 {
            color: #00ff88;
            margin-bottom: 10px;
        }
        
        .note p {
            color: #c0c0c0;
            font-size: 0.95em;
        }
        
        .samples {
            display: flex;
            flex-direction: column;
            gap: 60px;
            margin-top: 40px;
        }
        
        .sample {
            background: rgba(255, 255, 255, 0.03);
            border-radius: 15px;
            padding: 30px;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        .sample h2 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 2em;
        }
        
        .sample-image {
            width: 100%;
            border-radius: 10px;
            margin: 20px 0;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.5);
            cursor: pointer;
            transition: transform 0.3s ease;
        }
        
        .sample-image:hover {
            transform: scale(1.02);
        }
        
        .description {
            color: #c0c0c0;
            font-size: 1.1em;
            margin: 20px 0;
        }
        
        .features {
            list-style: none;
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
            margin: 25px 0;
        }
        
        .features li {
            padding: 12px 15px;
            background: rgba(102, 126, 234, 0.1);
            border-radius: 8px;
            color: #a0a0a0;
            font-size: 0.9em;
            border-left: 3px solid #667eea;
        }
        
        .features li:before {
            content: "‚úì ";
            color: #00ff88;
            font-weight: bold;
            margin-right: 8px;
        }
        
        footer {
            margin-top: 80px;
            text-align: center;
            color: #666;
            font-size: 0.9em;
            padding-top: 40px;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        .badge {
            display: inline-block;
            padding: 6px 12px;
            background: rgba(0, 255, 136, 0.2);
            color: #00ff88;
            border-radius: 15px;
            font-size: 0.8em;
            font-weight: 600;
            margin-right: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üèÄ Basketball Analysis Templates</h1>
            <p class="subtitle">Visual Mockups - ShotStack Video Editing API Integration</p>
            <span class="badge">3 Templates</span>
            <span class="badge">Real-Time Analysis</span>
            <span class="badge">Professional Overlays</span>
        </header>
        
        <div class="note">
            <h3>üìù About These Samples</h3>
            <p>
                These are static mockups demonstrating what the ShotStack video templates will produce. 
                In production, these overlays will be applied to actual basketball shooting videos with 
                real-time pose detection data from RoboFlow. The templates are fully functional and ready 
                to integrate with your analysis pipeline.
            </p>
        </div>
        
        <div class="samples">
"""
    
    for result in results:
        if result:
            # Convert absolute path to relative for HTML
            img_filename = os.path.basename(result['path'])
            
            html += f"""
            <div class="sample">
                <h2>{result['name']}</h2>
                <p class="description">{result['description']}</p>
                
                <img src="{img_filename}" alt="{result['name']}" class="sample-image" 
                     onclick="window.open('{img_filename}', '_blank')">
                
                <ul class="features">
"""
            
            for feature in result['features']:
                html += f"                    <li>{feature}</li>\n"
            
            html += """                </ul>
            </div>
"""
    
    html += """
        </div>
        
        <footer>
            <p><strong>Integration Ready:</strong> These templates can be activated with your ShotStack API credentials.</p>
            <p>Click any image to view full size</p>
            <p style="margin-top: 20px; color: #444;">Generated: """ + __import__('time').strftime('%Y-%m-%d %H:%M:%S') + """</p>
        </footer>
    </div>
</body>
</html>
"""
    
    return html


def main():
    """Main execution"""
    print("=" * 70)
    print("üé® SHOTSTACK TEMPLATE MOCKUP GENERATOR")
    print("=" * 70)
    print("\n Creating static visual samples of basketball analysis templates")
    print()
    
    # Create output directory
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    print(f"üìÅ Output directory: {OUTPUT_DIR}\n")
    
    # Generate all samples
    results = []
    
    try:
        result1 = create_sample_1_form_analysis()
        if result1:
            results.append(result1)
        
        result2 = create_sample_2_coaching_feedback()
        if result2:
            results.append(result2)
        
        result3 = create_sample_3_split_screen()
        if result3:
            results.append(result3)
        
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    
    # Create HTML preview
    if results:
        html_content = create_html_preview(results)
        html_file = os.path.join(OUTPUT_DIR, 'template_previews.html')
        with open(html_file, 'w') as f:
            f.write(html_content)
        
        print(f"\nüìÑ HTML preview created: {html_file}")
        
        # Save results as JSON
        results_json = os.path.join(OUTPUT_DIR, 'mockup_results.json')
        with open(results_json, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"üíæ Results saved: {results_json}")
    
    # Print summary
    print("\n" + "=" * 70)
    print("üìä GENERATION SUMMARY")
    print("=" * 70)
    for result in results:
        print(f"‚úÖ {result['name']}")
        print(f"   üì∏ {result['path']}")
    
    print(f"\nüéâ All mockups created! Open the HTML file to view:")
    print(f"   file://{os.path.join(OUTPUT_DIR, 'template_previews.html')}")
    print()


if __name__ == "__main__":
    main()
