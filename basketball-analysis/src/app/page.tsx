/**
 * @file page.tsx (Home Page)
 * @description Main upload page for basketball shooting analysis
 * 
 * PURPOSE:
 * - Provides the primary upload interface for images and videos
 * - Handles media type selection (image/video toggle)
 * - Orchestrates the analysis flow (upload ‚Üí analyze ‚Üí results)
 * - Manages the analysis progress screen
 * 
 * KEY FEATURES:
 * - Image upload: 3-7 photos via MediaUpload component
 * - Video upload: Up to 10-second video via VideoUploadInline
 * - Player profile form (optional)
 * - Analysis progress tracking
 * - Session saving to localStorage
 * 
 * FLOW:
 * 1. User selects media type (image/video)
 * 2. User uploads media via respective component
 * 3. User clicks "Analyze" button
 * 4. handleAnalyze() ‚Üí handleImageAnalysis() or handleVideoAnalysis()
 * 5. Progress screen shows during analysis
 * 6. Redirects to /results/demo on completion
 * 
 * RELATED FILES:
 * - src/components/upload/MediaUpload.tsx - Image upload component
 * - src/components/upload/VideoUploadInline.tsx - Video upload component
 * - src/services/visionAnalysis.ts - Image analysis service
 * - src/services/videoAnalysis.ts - Video analysis service
 * - src/stores/analysisStore.ts - State management
 * - src/app/results/demo/page.tsx - Results display page
 */
"use client"

import React, { useState, useRef, useEffect, Suspense, useCallback, useMemo } from "react"
import { useRouter, useSearchParams } from "next/navigation"
import { Upload, User, Sparkles, Video, Image as ImageIcon, ChevronDown } from "lucide-react"
import { MediaUpload } from "@/components/upload/MediaUpload"
import { VideoUploadInline } from "@/components/upload/VideoUploadInline"
import { PlayerProfileForm } from "@/components/upload/PlayerProfileForm"
import { useAnalysisStore } from "@/stores/analysisStore"
import { useAuthStore } from "@/stores/authStore"
import { useProfileStore } from "@/stores/profileStore"
import { analyzeShootingForm } from "@/services/visionAnalysis"
import { analyzeVideoShooting, convertVideoToSessionFormat } from "@/services/videoAnalysis"
import { AnalysisProgressScreen, type InputType } from "@/components/analysis/AnalysisProgressScreen"
import { 
  saveSession, 
  createSessionFromAnalysis,
  type SessionScreenshot 
} from "@/services/sessionStorage"
import { detectFlawsFromAngles, getShooterLevel } from "@/data/shootingFlawsDatabase"
import { cn } from "@/lib/utils"
import type { VisionAnalysisResult } from "@/stores/analysisStore"

type MediaType = "image" | "video"

// Wrapper component to handle Suspense for useSearchParams
export default function Home() {
  return (
    <Suspense fallback={<div className="min-h-screen bg-[#1a1a1a] flex items-center justify-center"><div className="text-[#FFD700] text-xl">Loading...</div></div>}>
      <HomeContent />
    </Suspense>
  )
}

function HomeContent() {
  const router = useRouter()
  const searchParams = useSearchParams()
  const [mediaType, setMediaType] = useState<MediaType>("image")
  
  // Video file state (managed here for unified flow) - declare before useEffect
  const [videoFile, setVideoFile] = useState<File | null>(null)
  
  // Get store functions first before using them in useEffect
  const { 
    uploadedFile, 
    setIsAnalyzing, 
    setAnalysisProgress, 
    setVisionAnalysisResult, 
    setUploadedImageBase64, 
    setRoboflowBallDetection,
    setVideoAnalysisData,
    setMediaType: setStoreMediaType,
    setError,
    resetUpload,
    mediaType: storeMediaType,
    setUploadedFile,
    setMediaPreviewUrl,
    setTeaserFrames,
    setFullFrames,
    setAllUploadedUrls,
    setFormAnalysisResult,
    setPlayerProfile
  } = useAnalysisStore()
  
  // Get auth and profile stores for auto-population
  const { user, isAuthenticated } = useAuthStore()
  const profileStore = useProfileStore()
  
  // Auto-populate player profile from profileStore when authenticated
  useEffect(() => {
    if (isAuthenticated && user && profileStore.profileComplete) {
      // Convert profileStore data to playerProfile format
      const playerProfile = {
        name: user.displayName || `${user.firstName || ''} ${user.lastName || ''}`.trim() || user.email.split('@')[0],
        email: user.email,
        age: profileStore.age || undefined,
        height: profileStore.heightInches ? `${Math.floor(profileStore.heightInches / 12)}'${profileStore.heightInches % 12}"` : undefined,
        weight: profileStore.weightLbs ? `${profileStore.weightLbs} lbs` : undefined,
        wingspan: profileStore.wingspanInches ? `${Math.floor(profileStore.wingspanInches / 12)}'${profileStore.wingspanInches % 12}"` : undefined,
        skillLevel: profileStore.experienceLevel?.toUpperCase() as any,
        bodyType: profileStore.bodyType?.toUpperCase() as any,
      }
      setPlayerProfile(playerProfile)
    }
  }, [isAuthenticated, user, profileStore.profileComplete, profileStore.age, profileStore.heightInches, profileStore.weightLbs, profileStore.wingspanInches, profileStore.experienceLevel, profileStore.bodyType, setPlayerProfile])
  
  // Check if coming from results page for a new session (skip profile)
  const isNewSession = searchParams.get('mode') === 'video' || searchParams.get('mode') === 'image'
  
  // Set media type from URL query parameter on mount
  useEffect(() => {
    const mode = searchParams.get('mode')
    if (mode === 'video') {
      setMediaType('video')
      setStoreMediaType('VIDEO')
    } else if (mode === 'image') {
      setMediaType('image')
      setStoreMediaType('IMAGE')
    }
  }, [searchParams, setStoreMediaType])

  // Clear state when switching between media types
  useEffect(() => {
    // When switching to image mode, clear video-specific state
    // Keep image-related state (uploadedImageBase64, visionAnalysisResult) as both modes use these
    if (mediaType === 'image' && storeMediaType === 'VIDEO') {
      setVideoFile(null)
      setVideoAnalysisData(null)
      setStoreMediaType('IMAGE')
    }
    // When switching to video mode, clear image upload state but keep image processing capabilities
    // Video mode extracts frames to images and uses the same image analysis components
    if (mediaType === 'video' && storeMediaType === 'IMAGE') {
      // Only clear upload-specific state, not image processing state
      // uploadedImageBase64 and visionAnalysisResult are used by video mode too
      setUploadedFile(null)
      setMediaPreviewUrl(null)
      setTeaserFrames([])
      setFullFrames([])
      setAllUploadedUrls([])
      setFormAnalysisResult(null)
      setStoreMediaType('VIDEO')
    }
  }, [mediaType, storeMediaType, setStoreMediaType, setVideoAnalysisData, setVideoFile, setUploadedFile, setMediaPreviewUrl, setTeaserFrames, setFullFrames, setAllUploadedUrls, setFormAnalysisResult])
  
  const [isDropdownOpen, setIsDropdownOpen] = useState(false)
  const [isSubmitting, setIsSubmitting] = useState(false)
  const [showProgressScreen, setShowProgressScreen] = useState(false)
  const [analysisError, setAnalysisError] = useState<string | null>(null)
  const [processingComplete, setProcessingComplete] = useState(false)
  const analysisResultRef = useRef<VisionAnalysisResult | null>(null)

  // Form is valid if we have images (for image mode) or video file (for video mode)
  const isFormValid = mediaType === "image" ? Boolean(uploadedFile) : Boolean(videoFile)

  // Determine input type for processing time estimate
  const getInputType = (): InputType => {
    if (mediaType === "video") return "1_video"
    return "3_images"
  }

  const handleAnalyze = async () => {
    if (!isFormValid) return

    setIsSubmitting(true)
    setIsAnalyzing(true)
    setShowProgressScreen(true)
    setProcessingComplete(false)
    setAnalysisProgress(0)
    setAnalysisError(null)
    analysisResultRef.current = null

    try {
      if (mediaType === "video" && videoFile) {
        // VIDEO ANALYSIS FLOW
        await handleVideoAnalysis()
      } else if (mediaType === "image" && uploadedFile) {
        // IMAGE ANALYSIS FLOW
        await handleImageAnalysis()
      }
    } catch (error) {
      console.error("Analysis failed:", error)
      const message = error instanceof Error ? error.message : "Analysis failed"
      setAnalysisError(message)
      setError(message)
      setShowProgressScreen(false)
      setIsSubmitting(false)
      setIsAnalyzing(false)
    }
  }

  const handleImageAnalysis = async () => {
    if (!uploadedFile) return

    setAnalysisProgress(10)
    
    // IMPORTANT: Set media type to IMAGE so results page shows image mode
    setStoreMediaType("IMAGE")
    
    // Convert file to base64 for persistence across navigation
    const reader = new FileReader()
    const base64Promise = new Promise<string>((resolve, reject) => {
      reader.onload = () => resolve(reader.result as string)
      reader.onerror = reject
      reader.readAsDataURL(uploadedFile)
    })
    
    const base64 = await base64Promise
    setUploadedImageBase64(base64)
    
    setAnalysisProgress(20)
    
    // STEP 1: Call Roboflow to detect the basketball FIRST
    console.log("üèÄ Step 1: Detecting basketball with Roboflow...")
    let roboflowBall: { x: number; y: number; width: number; height: number; confidence: number } | null = null
    try {
      const roboflowResponse = await fetch('/api/detect-basketball', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ image: base64 }),
      })
      const roboflowResult = await roboflowResponse.json()
      
      if (roboflowResult.success && roboflowResult.basketball) {
        console.log("üèÄ Basketball FOUND:", roboflowResult.basketball)
        roboflowBall = roboflowResult.basketball
        setRoboflowBallDetection(roboflowBall)
      } else {
        console.log("üèÄ No basketball detected by Roboflow:", roboflowResult.message || roboflowResult.error)
        setRoboflowBallDetection(null)
      }
    } catch (roboflowError) {
      console.error("üèÄ Roboflow detection failed (continuing with Vision AI):", roboflowError)
      setRoboflowBallDetection(null)
    }
    
    setAnalysisProgress(40)
    
    // STEP 2: Call Vision AI to analyze the image
    console.log("ü§ñ Step 2: Analyzing with Vision AI...")
    const ballPositionForVision = roboflowBall ? {
      x: roboflowBall.x,
      y: roboflowBall.y,
      confidence: roboflowBall.confidence
    } : null
    
    if (ballPositionForVision) {
      console.log("üéØ Using Roboflow ball position as anchor:", ballPositionForVision)
    }
    
    // Get profile data for personalized analysis
    const profileData = isAuthenticated && profileStore.profileComplete ? {
      heightInches: profileStore.heightInches,
      weightLbs: profileStore.weightLbs,
      age: profileStore.age,
      experienceLevel: profileStore.experienceLevel,
      dominantHand: profileStore.dominantHand,
      shootingStyle: profileStore.shootingStyle,
    } : undefined
    
    const result = await analyzeShootingForm(uploadedFile, ballPositionForVision, profileData)
    
    setAnalysisProgress(80)

    if (!result.success) {
      throw new Error(result.error || "Analysis failed")
    }

    // Store result for later use
    analysisResultRef.current = result as VisionAnalysisResult
    
    // Store the result
    setVisionAnalysisResult(result as VisionAnalysisResult)
    setAnalysisProgress(100)
    
    // Signal that actual processing is complete
    setProcessingComplete(true)
    
    // Auto-save session to localStorage
    try {
      const overallScore = result.overall_score || 70
      const detectedFlaws = result.angles 
        ? detectFlawsFromAngles(result.angles).map(f => f.name)
        : []
      const shooterLevel = getShooterLevel(overallScore)
      
      const screenshots: SessionScreenshot[] = []
      
      const session = createSessionFromAnalysis(
        base64,
        base64,
        screenshots,
        {
          overallScore,
          shooterLevel: shooterLevel.name,
          angles: result.angles || {},
          detectedFlaws,
          measurements: {}
        },
        (isAuthenticated && user?.displayName) || useAnalysisStore.getState().playerProfile.name || 'Player',
        undefined, // coachingLevelUsed
        undefined, // profileSnapshot
        undefined, // imagesAnalyzed
        'image', // mediaType - explicitly set to 'image'
        undefined // videoData
      )
      
      const saved = saveSession(session)
      if (saved) {
        console.log("‚úÖ Image session saved to localStorage:", session.id, "mediaType:", session.mediaType)
      }
      
    } catch (saveError) {
      console.error("Error saving session:", saveError)
    }
  }

  const handleVideoAnalysis = async () => {
    if (!videoFile) return

    setAnalysisProgress(10)
    console.log("üìπ Starting video analysis...")

    // Get profile data for personalized analysis
    const profileData = isAuthenticated && profileStore.profileComplete ? {
      heightInches: profileStore.heightInches,
      weightLbs: profileStore.weightLbs,
      age: profileStore.age,
      experienceLevel: profileStore.experienceLevel,
      dominantHand: profileStore.dominantHand,
      shootingStyle: profileStore.shootingStyle,
    } : undefined
    
    // Call the video analysis service
    const analysisResult = await analyzeVideoShooting(videoFile, profileData)

    setAnalysisProgress(60)

    if (!analysisResult.success) {
      throw new Error(analysisResult.error || 'Video analysis failed')
    }

    setAnalysisProgress(80)

    // Convert to session format
    const sessionData = convertVideoToSessionFormat(analysisResult)
    
    // Store in analysis store for results page
    setUploadedImageBase64(sessionData.mainImageBase64)
    
    // Create vision analysis result format for compatibility
    const visionResult = {
      success: true,
      overall_score: sessionData.overallScore,
      keypoints: sessionData.keypoints || undefined,
      angles: sessionData.angles,
      feedback: sessionData.feedback.map(msg => ({ type: 'info', area: 'general', message: msg })),
      analysis: {
        overallScore: sessionData.overallScore,
        category: sessionData.overallScore >= 85 ? 'EXCELLENT' : sessionData.overallScore >= 65 ? 'GOOD' : 'NEEDS_IMPROVEMENT',
        bodyPositions: {},
        strengths: sessionData.strengths,
        improvements: sessionData.improvements,
        measurements: sessionData.angles
      }
    }
    
    setVisionAnalysisResult(visionResult as unknown as VisionAnalysisResult)
    analysisResultRef.current = visionResult as unknown as VisionAnalysisResult
    
    // Store video analysis data in the store for results page
    const videoData = {
      annotatedFramesBase64: analysisResult.annotated_frames_base64 || [],
      frameCount: analysisResult.frame_count || 0,
      duration: analysisResult.video_info?.duration || 0,
      fps: analysisResult.video_info?.target_fps || 10,
      phases: analysisResult.phases || [],
      metrics: analysisResult.metrics || {
        elbow_angle_range: { min: null, max: null, at_release: null },
        knee_angle_range: { min: null, max: null },
        release_frame: 0,
        release_timestamp: 0
      },
      frameData: (analysisResult.frame_data || []).map((fd: { frame: number; timestamp: number; phase: string; metrics: Record<string, number>; keypoints?: Record<string, { x: number; y: number; confidence: number }> }) => ({
        frame: fd.frame,
        timestamp: fd.timestamp,
        phase: fd.phase,
        metrics: fd.metrics,
        keypoints: fd.keypoints
      })),
      // Include keypoints for each frame for drawing overlays
      allKeypoints: analysisResult.all_keypoints || (analysisResult.frame_data || []).map((fd: { keypoints?: Record<string, { x: number; y: number; confidence: number }> }) => fd.keypoints || {})
    }
    setVideoAnalysisData(videoData)
    setStoreMediaType("VIDEO") // Mark as video in the store

    setAnalysisProgress(90)

    // Create and save session with video data
    const detectedFlaws = detectFlawsFromAngles(sessionData.angles).map(f => f.name)
    const shooterLevel = getShooterLevel(sessionData.overallScore)
    
    const screenshots: SessionScreenshot[] = sessionData.screenshots.map((ss, idx) => ({
      id: `video-${idx}`,
      label: ss.label,
      imageBase64: ss.imageBase64,
      analysis: ss.analysis
    }))
    
    const session = createSessionFromAnalysis(
      sessionData.mainImageBase64,
      sessionData.skeletonImageBase64,
      screenshots,
      {
        overallScore: sessionData.overallScore,
        shooterLevel: shooterLevel.name,
        angles: sessionData.angles,
        detectedFlaws,
        measurements: sessionData.angles
      },
      useAnalysisStore.getState().playerProfile.name || 'Player',
      undefined,
      undefined,
      analysisResult.key_screenshots?.length || 3,
      'video',  // mediaType
      videoData  // video data with all frames
    )
    
    const saved = saveSession(session)
    if (saved) {
      console.log("‚úÖ Video session saved to localStorage:", session.id, "mediaType:", session.mediaType)
    }

    setAnalysisProgress(100)
    setProcessingComplete(true)
  }

  // Called when progress screen animation completes
  const handleProgressComplete = useCallback(() => {
    setShowProgressScreen(false)
    setIsSubmitting(false)
    setIsAnalyzing(false)
    router.push("/results/demo")
  }, [router, setIsAnalyzing])

  // Called when user cancels during processing
  const handleCancel = useCallback(() => {
    setShowProgressScreen(false)
    setIsSubmitting(false)
    setIsAnalyzing(false)
    setProcessingComplete(false)
    setAnalysisError(null)
  }, [setIsAnalyzing])

  // Called when user wants to retry after error
  const handleRetry = useCallback(() => {
    setAnalysisError(null)
    handleAnalyze()
  }, [])

  // Memoize media options to prevent re-creation on every render
  const mediaOptions = useMemo(() => [
    { value: "image" as MediaType, label: "Images", icon: ImageIcon, description: "Upload 3-7 photos of your shot" },
    { value: "video" as MediaType, label: "Video", icon: Video, description: "Upload a 10-second video" }
  ], [])

  const selectedOption = useMemo(() => 
    mediaOptions.find(o => o.value === mediaType)!
  , [mediaOptions, mediaType])

  return (
    <>
      <AnalysisProgressScreen 
        isVisible={showProgressScreen}
        inputType={getInputType()}
        actualProcessingComplete={processingComplete}
        errorMessage={analysisError}
        onComplete={handleProgressComplete}
        onCancel={handleCancel}
        onRetry={handleRetry}
      />
      
      <main className="min-h-[calc(100vh-200px)] py-8 px-4 bg-[#050505]">
        <div className="container mx-auto max-w-4xl">
          {/* Main Card Container */}
          <div className="bg-[#2C2C2C] rounded-lg overflow-hidden shadow-lg">
            {/* Upload Section */}
            <div className="p-6 border-b border-[#3a3a3a]">
              <div className="flex items-center gap-3 mb-2">
                <Upload className="w-5 h-5 text-[#FFD700]" />
                <h2 className="text-[#FFD700] font-semibold text-lg">Upload Your Shooting Media</h2>
              </div>
              <p className="text-[#E5E5E5] text-sm mb-6">
                Choose to upload images or a video of your shooting form for comprehensive biomechanical analysis.
              </p>

              {/* Media Type Selector - Premium Dropdown */}
              <div className="mb-6">
                <label className="text-[#888] text-xs uppercase tracking-wider mb-2 block">
                  Select Media Type
                </label>
                <div className="relative">
                  <button
                    type="button"
                    onClick={() => setIsDropdownOpen(!isDropdownOpen)}
                    className={cn(
                      "w-full bg-gradient-to-r from-[#1a1a1a] to-[#252525] border-2 rounded-xl p-4 flex items-center justify-between transition-all duration-200",
                      isDropdownOpen 
                        ? "border-[#FFD700] shadow-lg shadow-[#FFD700]/10" 
                        : "border-[#3a3a3a] hover:border-[#4a4a4a]"
                    )}
                  >
                    <div className="flex items-center gap-4">
                      <div className={cn(
                        "w-12 h-12 rounded-lg flex items-center justify-center",
                        mediaType === "image" 
                          ? "bg-gradient-to-br from-blue-500/20 to-purple-500/20 border border-blue-500/30"
                          : "bg-gradient-to-br from-orange-500/20 to-red-500/20 border border-orange-500/30"
                      )}>
                        <selectedOption.icon className={cn(
                          "w-6 h-6",
                          mediaType === "image" ? "text-blue-400" : "text-orange-400"
                        )} />
                      </div>
                      <div className="text-left">
                        <div className="text-[#E5E5E5] font-semibold text-lg">{selectedOption.label}</div>
                        <div className="text-[#888] text-sm">{selectedOption.description}</div>
                      </div>
                    </div>
                    <ChevronDown className={cn(
                      "w-5 h-5 text-[#888] transition-transform duration-200",
                      isDropdownOpen && "rotate-180"
                    )} />
                  </button>

                  {/* Dropdown Options */}
                  {isDropdownOpen && (
                    <div className="absolute top-full left-0 right-0 mt-2 bg-[#1a1a1a] border border-[#3a3a3a] rounded-xl overflow-hidden shadow-xl z-10">
                      {mediaOptions.map((option) => (
                        <button
                          key={option.value}
                          type="button"
                          onClick={() => {
                            const newMediaType = option.value
                            setMediaType(newMediaType)
                            setIsDropdownOpen(false)
                            
                            // Clear the other type's state when switching
                            if (newMediaType === "image") {
                              setVideoFile(null)
                              setStoreMediaType("IMAGE")
                              // Clear video-related state from store
                              setVideoAnalysisData(null)
                            } else if (newMediaType === "video") {
                              resetUpload()
                              setStoreMediaType("VIDEO")
                            }
                          }}
                          className={cn(
                            "w-full p-4 flex items-center gap-4 transition-all duration-150",
                            mediaType === option.value 
                              ? "bg-[#FFD700]/10 border-l-4 border-[#FFD700]"
                              : "hover:bg-[#252525] border-l-4 border-transparent"
                          )}
                        >
                          <div className={cn(
                            "w-10 h-10 rounded-lg flex items-center justify-center",
                            option.value === "image" 
                              ? "bg-blue-500/20 border border-blue-500/30"
                              : "bg-orange-500/20 border border-orange-500/30"
                          )}>
                            <option.icon className={cn(
                              "w-5 h-5",
                              option.value === "image" ? "text-blue-400" : "text-orange-400"
                            )} />
                          </div>
                          <div className="text-left flex-1">
                            <div className={cn(
                              "font-medium",
                              mediaType === option.value ? "text-[#FFD700]" : "text-[#E5E5E5]"
                            )}>
                              {option.label}
                            </div>
                            <div className="text-[#888] text-sm">{option.description}</div>
                          </div>
                          {mediaType === option.value && (
                            <div className="w-2 h-2 rounded-full bg-[#FFD700]" />
                          )}
                        </button>
                      ))}
                    </div>
                  )}
                </div>
              </div>

              {/* Conditional Upload Component */}
              {mediaType === "image" ? (
                <MediaUpload />
              ) : (
                <VideoUploadInline 
                  videoFile={videoFile}
                  onVideoFileChange={setVideoFile}
                />
              )}
            </div>

            {/* Player Profile Section - Only show for first-time users (not when coming from results page) */}
            {!isNewSession && (
              <div className="p-6 border-b border-[#3a3a3a]">
                <div className="flex items-center gap-3 mb-2">
                  <User className="w-5 h-5 text-[#FFD700]" />
                  <h2 className="text-[#FFD700] font-semibold text-lg">Player Profile</h2>
                </div>
                <p className="text-[#E5E5E5] text-sm mb-6">
                  Fill out your information for personalized analysis and elite shooter matching.
                </p>
                <PlayerProfileForm />
              </div>
            )}

            {/* Submit Button Section */}
            <div className="p-6">
              <button
                onClick={handleAnalyze}
                disabled={!isFormValid || isSubmitting}
                className="w-full bg-[#FFD700] hover:bg-[#e6c200] disabled:bg-[#4a4a4a] disabled:text-[#888] text-[#1a1a1a] font-medium py-4 px-6 rounded-xl transition-all duration-200 flex items-center justify-center gap-2 text-lg shadow-lg hover:shadow-[#FFD700]/20"
              >
                {isSubmitting ? (
                  <>
                    <div className="w-5 h-5 border-2 border-[#1a1a1a] border-t-transparent rounded-full animate-spin" />
                    Analyzing...
                  </>
                ) : (
                  <>
                    <Sparkles className="w-5 h-5" />
                    Analyze My Shooting Form
                  </>
                )}
              </button>
              <p className="text-[#888] text-sm text-center mt-3">
                {mediaType === "image" 
                  ? "Requires at least 3 uploaded images; profile is optional."
                  : "Requires a video (max 10 seconds); profile is optional."
                }
              </p>
              {analysisError && (
                <p className="text-red-400 text-sm text-center mt-3 bg-red-900/20 p-3 rounded-md">
                  ‚ö†Ô∏è {analysisError}
                </p>
              )}
            </div>
          </div>
        </div>
      </main>
    </>
  )
}
